{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions and Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/oxford.jpg')\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 3 x 3 kernel\n",
    "kernel_3x3 = np.ones((3, 3), np.float32) / 9\n",
    "\n",
    "#  cv2.fitler2D to conovlve the kernal with an image \n",
    "blurred = cv2.filter2D(image, -1, kernel_3x3)\n",
    "cv2.imshow('3x3 Kernel Blurring', blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 7 x 7 kernel\n",
    "kernel_7x7 = np.ones((7, 7), np.float32) / 49\n",
    "\n",
    "blurred2 = cv2.filter2D(image, -1, kernel_7x7)\n",
    "cv2.imshow('7x7 Kernel Blurring', blurred2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other blurring methods \n",
    "- Gaussian Blurring\n",
    "- Median Blurring\n",
    "- Bilateral Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging done by convolving the image with a normalized box filter. \n",
    "# This takes the pixels under the box and replaces the central element\n",
    "# Box size needs to odd and positive \n",
    "blur = cv2.blur(image, (3,3))\n",
    "cv2.imshow('Averaging', blur)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Instead of box filter, gaussian kernel\n",
    "Gaussian = cv2.GaussianBlur(image, (3,3), 0)\n",
    "cv2.imshow('Gaussian Blurring', Gaussian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Takes median of all the pixels under kernel area and central element is replaced with this median value\n",
    "median = cv2.medianBlur(image, 3)\n",
    "cv2.imshow('Median Blurring', median)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Bilateral is very effective in noise removal while keeping edges sharp\n",
    "bilateral = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "cv2.imshow('Bilateral Blurring', bilateral)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral Filter\n",
    "#### dst = cv.bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]])\n",
    "- **src**\tSource 8-bit or floating-point, 1-channel or 3-channel image.\n",
    "- **dst**\tDestination image of the same size and type as src .\n",
    "- **d**\tDiameter of each pixel neighborhood that is used during filtering. If it is non-positive, it is computed from sigmaSpace.\n",
    "- **sigmaColor**\tFilter sigma in the color space. A larger value of the parameter means that farther colors within the pixel neighborhood (see sigmaSpace) will be mixed together, resulting in larger areas of semi-equal color.\n",
    "- **sigmaSpace**\tFilter sigma in the coordinate space. A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough (see sigmaColor ). When d>0, it specifies the neighborhood size regardless of sigmaSpace. Otherwise, d is proportional to sigmaSpace.\n",
    "- **borderType**\tborder mode used to extrapolate pixels outside of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image De-noising - Non-Local Means Denoising\n",
    "\n",
    "**There are 4 variations of Non-Local Means Denoising:**\n",
    "\n",
    "- cv2.fastNlMeansDenoising() - works with a single grayscale images\n",
    "- cv2.fastNlMeansDenoisingColored() - works with a color image.\n",
    "- cv2.fastNlMeansDenoisingMulti() - works with image sequence captured in short period of time (grayscale images)\n",
    "- cv2.fastNlMeansDenoisingColoredMulti() - same as above, but for color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters, after None are - the filter strength 'h' (5-10 is a good range)\n",
    "# Next is hForColorComponents, set as same value as h again\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(image, None, 6, 6, 7, 21)\n",
    "\n",
    "cv2.imshow('Fast Means Denoising', dst)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for fastNlMeansDenoisingColored:\t\n",
    "\n",
    "fastNlMeansDenoisingColored(InputArray src, OutputArray dst, float h=3, float hColor=3, int templateWindowSize=7, int searchWindowSize=21 )¶\n",
    "\n",
    "- **src** – Input 8-bit 3-channel image.\n",
    "- **dst** – Output image with the same size and type as src .\n",
    "templateWindowSize – Size in pixels of the template patch that is used to compute weights. Should be odd. Recommended value 7 pixels\n",
    "- **searchWindowSize** – Size in pixels of the window that is used to compute weighted average for given pixel. Should be odd. Affect performance linearly: greater searchWindowsSize - greater denoising time. Recommended value 21 pixels\n",
    "- **h** – Parameter regulating filter strength for luminance component. Bigger h value perfectly removes noise but also removes image details, smaller h value preserves details but also preserves some noise\n",
    "- **hColor** – The same as h but for color components. For most images value equals 10 will be enought to remove colored noise and do not distort colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Original', image)\n",
    "\n",
    "# Create our shapening kernel, remember it must sum to one \n",
    "kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                              [-1, 9,-1],\n",
    "                              [-1,-1,-1]])\n",
    "\n",
    "# applying the sharpening kernel to the image\n",
    "sharpened = cv2.filter2D(image, -1, kernel_sharpening)\n",
    "cv2.imshow('Sharpened Image', sharpened)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding, Binarization & Adaptive Thresholding\n",
    "\n",
    "In thresholding, we convert a grey scale image to it's binary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread('images/gradient.jpg',0)\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "# Values below 127 goes to 0 (black, everything above goes to 255 (white)\n",
    "ret,thresh1 = cv2.threshold(image, 200, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('1 Threshold Binary', thresh1)\n",
    "\n",
    "# Values below 127 go to 255 and values above 127 go to 0 (reverse of above)\n",
    "ret,thresh2 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('2 Threshold Binary Inverse', thresh2)\n",
    "\n",
    "# Values above 127 are truncated (held) at 127 (the 255 argument is unused)\n",
    "ret,thresh3 = cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)\n",
    "cv2.imshow('3 THRESH TRUNC', thresh3)\n",
    "\n",
    "# Values below 127 go to 0, above 127 are unchanged  \n",
    "ret,thresh4 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)\n",
    "cv2.imshow('4 THRESH TOZERO', thresh4)\n",
    "\n",
    "# Reverse of the above, below 127 is unchanged, above 127 goes to 0\n",
    "ret,thresh5 = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('5 THRESH TOZERO INV', thresh5)\n",
    "cv2.waitKey(0) \n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No specific value Adaptive thresholding. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread('images/Origin_of_Species.jpg', 0)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Values below 127 goes to 0 (black, everything above goes to 255 (white)\n",
    "ret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary', thresh1)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# blur images to removes noise\n",
    "image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "# Using adaptiveThreshold\n",
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5) \n",
    "cv2.imshow(\"Adaptive Mean Thresholding\", thresh) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "_, th2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Otsu's Thresholding\", th2) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Guassian Otsu's Thresholding\", th3) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2.adaptiveThreshold Parameters\n",
    "\n",
    "**cv2.adaptiveThreshold**(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) → dst\n",
    "\n",
    "- **src** – Source 8-bit single-channel image.\n",
    "- **dst** – Destination image of the same size and the same type as src .\n",
    "- **maxValue** – Non-zero value assigned to the pixels for which the condition is satisfied. See the details below.\n",
    "- **adaptiveMethod** – Adaptive thresholding algorithm to use, ADAPTIVE_THRESH_MEAN_C or ADAPTIVE_THRESH_GAUSSIAN_C . See the details below.\n",
    "- **thresholdType** – Thresholding type that must be either THRESH_BINARY or THRESH_BINARY_INV .\n",
    "- **blockSize** – Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on.\n",
    "- **C** – Constant subtracted from the mean or weighted mean. Normally, it is positive but may be zero or negative as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/opencv_inv.png', 0)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "# erode\n",
    "erosion = cv2.erode(image, kernel, iterations = 1)\n",
    "cv2.imshow('Erosion', erosion)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Dilate here\n",
    "dilation = cv2.dilate(image, kernel, iterations = 1)\n",
    "cv2.imshow('Dilation', dilation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Opening - Good for removing noise\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Opening', opening)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Closing - Good for removing noise\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('Closing', closing)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection & Image Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread('images/oxford.jpg',0)\n",
    "\n",
    "# Canny Edge Detection uses gradient values as thresholds\n",
    "# The first threshold gradient\n",
    "canny = cv2.Canny(image, 50, 120)\n",
    "cv2.imshow('Canny 1', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image, 10, 170)\n",
    "cv2.imshow('Canny 2', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image, 80, 100)\n",
    "cv2.imshow('Canny 3', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image, 60, 110)\n",
    "cv2.imshow('Canny 4', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = image.shape\n",
    "\n",
    "# Extract Sobel Edges\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X', sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y', sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "cv2.imshow('sobel_OR', sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "cv2.imshow('Laplacian', laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    " \n",
    "##  Then, we need to provide two values: threshold1 and threshold2.\n",
    "#Any gradient value larger than threshold2 # is considered to be an edge.\n",
    "#Any value below threshold1 is considered not to be an edge. \n",
    "#Values in between threshold1 and threshold2 are either as edges or non-edges based on their intensities are “connected”. \n",
    "\n",
    "# Canny Edge Detection uses gradient values as thresholds first threshold gradient\n",
    "canny = cv2.Canny(image, 50, 120)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CANNY\n",
    "\n",
    "canny = cv2.Canny(image, 50, 120)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image, 10, 200)\n",
    "cv2.imshow('Canny Wide', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image, 200, 240)\n",
    "cv2.imshow('Canny Narrow', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image, 70, 110)\n",
    "cv2.imshow('Canny 3', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
