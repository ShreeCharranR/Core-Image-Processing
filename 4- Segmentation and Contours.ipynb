{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contours in OpenCV\n",
    "- Finding contours\n",
    "- Drawing contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('images/house.jpg')\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# Draw all contours\n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), thickness = 2)\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cv2.findContours()\n",
    "\n",
    "**cv2.findContours(image, Retrieval Mode, Approximation Method)**\n",
    "\n",
    "Returns -> contours, hierarchy\n",
    "\n",
    "### Approximation Methods\n",
    "\n",
    "Using cv2.CHAIN_APPROX_NONE stores all the boundary points. But we don't necessarily need all bounding points. If the points form a straight line, we only need the start and ending points of that line.\n",
    "\n",
    "Using cv2.CHAIN_APPROX_SIMPLE instead only provides these start and end points of bounding contours, thus resulting in much more efficent storage of contour information.\n",
    "\n",
    "### Retrieval Modes (the first two are the most useful)\n",
    "- cv2.RETR_LIST – Retrieves all contours \n",
    "- cv2.RETR_EXTERNAL - Retrieves external or outer contours only\n",
    "- cv2.RETR_COMP - Retrieves all in a 2-level hierarchy\n",
    "- cv2.RETR_TREE - Retrieves all in full hierarchy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drawContours()\n",
    "\n",
    "**cv2.drawContours(image, contours, specific contour, color, thickness)**\n",
    "\n",
    "- The ‘contours’ parameter is the output from findContours\n",
    "- Specific contour relates to which contour you wish to draw e.g. Contour[0], Contour[1]. If you wish to draw all contours, use ‘-1’\n",
    "- color - BGR \n",
    "- thickness as we've seen previously it relates to line thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours found =  4\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('images/bunchofshapes.jpg')\n",
    "cv2.imshow('0 - Original Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Create a black image with same dimensions as our loaded image\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "\n",
    "# Create a copy of our original image\n",
    "orginal_image = image\n",
    "\n",
    "# Grayscale our image\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 50, 200)\n",
    "cv2.imshow('1 - Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find contours and print how many were found\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print (\"Number of contours found = \", len(contours))\n",
    "\n",
    "#Draw all contours\n",
    "cv2.drawContours(blank_image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('2 - All Contours over blank image', blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Draw all contours over blank image\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('3 - All Contours', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Contours by Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contor Areas before sorting\n",
      "[20587.5, 22901.5, 66579.5, 90222.0]\n",
      "Contor Areas after sorting\n",
      "[90222.0, 66579.5, 22901.5, 20587.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_contour_areas(contours):\n",
    "    \"\"\"returns the areas of all contours as list\"\"\"\n",
    "    all_areas = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    return all_areas\n",
    "\n",
    "image = cv2.imread('images/bunchofshapes.jpg')\n",
    "orginal_image = image\n",
    "\n",
    "# areas of the contours before sorting\n",
    "print(\"Contor Areas before sorting\")\n",
    "print(get_contour_areas(contours))\n",
    "\n",
    "# Sort contours \n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "#sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]\n",
    "\n",
    "print(\"Contor Areas after sorting\") \n",
    "print(get_contour_areas(sorted_contours))\n",
    "\n",
    "# Iterate over our contours and draw one at a time\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(orginal_image, [c], -1, (255,0,0), 3)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('Contours by area', orginal_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Contours Left to Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def x_cord_contour(contours):\n",
    "    \"\"\"Returns the X cordinate for the contour centroid\"\"\"\n",
    "    if cv2.contourArea(contours) > 10:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "def label_contour_center(image, c):\n",
    "    \"\"\"Places a red circle on the centers of contours\"\"\"\n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10'] / M['m00'])\n",
    "    cy = int(M['m01'] / M['m00'])\n",
    "    \n",
    "    # Draw the countour number on the image\n",
    "    cv2.circle(image,(cx,cy), 10, (0,0,255), -1)\n",
    "    return image\n",
    "\n",
    "\n",
    "image = cv2.imread('images/bunchofshapes.jpg')\n",
    "orginal_image = image.copy()\n",
    "\n",
    "# Computer Center of Mass or centroids and draw them on our image\n",
    "for (i, c) in enumerate(contours):\n",
    "    orig = label_contour_center(image, c)\n",
    " \n",
    "\"\"#   Showing the Contour centers\n",
    "cv2.imshow(\"Sorting Left to Right\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Sort by left to right using our x_cord_contour function\n",
    "contours_left_to_right = sorted(contours, key = x_cord_contour, reverse = False)\n",
    "\n",
    "\n",
    "# Labeling Contours left to right\n",
    "for (i,c)  in enumerate(contours_left_to_right):\n",
    "    cv2.drawContours(orginal_image, [c], -1, (0,0,255), 3)  \n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10'] / M['m00'])\n",
    "    cy = int(M['m01'] / M['m00'])\n",
    "    cv2.putText(orginal_image, str(i+1), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
    "    cv2.imshow('Sorting Left to Right', orginal_image)\n",
    "    cv2.waitKey(0)\n",
    "    (x, y, w, h) = cv2.boundingRect(c)  \n",
    "    \n",
    "    # crop each contour and save these images\n",
    "    #cropped_contour = orginal_image[y:y + h, x:x + w]\n",
    "    #image_name = \"output_shape_number_\" + str(i+1) + \".jpg\"\n",
    "    #print(image_name)\n",
    "    #cv2.imwrite(image_name, cropped_contour)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating Contours and Convex Hull \n",
    "\n",
    "***cv2.approxPolyDP(contour, Approximation Accuracy, Closed)***\n",
    "- **contour** – is the individual contour we wish to approximate\n",
    "- **Approximation Accuracy** – Important parameter is determining the accuracy of the approximation. Small values give precise-  approximations, large values give more generic approximation. A good rule of thumb is less than 5% of the contour perimeter\n",
    "- **Closed** – a Boolean value that states whether the approximate contour should be open or closed \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ApproxPolyDP to approximate contours as a more defined shape\n",
    "It approximates a contour shape to another shape with less number of vertices depending upon the precision we specify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/house.jpg')\n",
    "orig_image = image.copy()\n",
    "cv2.imshow('Original Image', orig_image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Grayscale and binarize\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours \n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "copy = image.copy()\n",
    "\n",
    "# Iterate through each contour \n",
    "for c in contours:\n",
    "    #x,y,w,h = cv2.boundingRect(c)\n",
    "    #cv2.rectangle(orig_image,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "    cv2.drawContours(image, [c], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Bounding Rectangle', image)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Iterate through each contour and compute the approx contour\n",
    "for c in contours:\n",
    "    # Calculate accuracy as a percent of the contour perimeter\n",
    "    accuracy = 0.03 * cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, accuracy, True)\n",
    "    cv2.drawContours(copy, [approx], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Approx Poly DP', copy)\n",
    "    \n",
    "cv2.waitKey(0)   \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex Hull\n",
    "\n",
    "Convex Hull will look similar to contour approximation, but it is not (Both may provide same results in some cases). Here, cv2.convexHull() function checks a curve for convexity defects and corrects it. Generally speaking, convex curves are the curves which are always bulged out, or at-least flat. And if it is bulged inside, it is called convexity defects. For example, check the below image of hand. Red line shows the convex hull of hand. The double-sided arrow marks shows the convexity defects, which are the local maximum deviations of hull from contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/hand.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Threshold the image\n",
    "ret, thresh = cv2.threshold(gray, 176, 255, 0)\n",
    "\n",
    "# Find contours \n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "# Sort Contors by area and then remove the largest frame contour\n",
    "n = len(contours) - 1\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=False)[:n]\n",
    "\n",
    "# Iterate through contours and draw the convex hull\n",
    "for c in contours:\n",
    "    hull = cv2.convexHull(c)\n",
    "    cv2.drawContours(image, [hull], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Convex Hull', image)\n",
    "\n",
    "cv2.waitKey(0)    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Line Detection - Using Hough Lines\n",
    "   \n",
    "**cv2.HoughLines**(binarized/thresholded image, 𝜌 accuracy, 𝜃 accuracy, threshold)\n",
    "- Threshold here is the minimum vote for it to be considered a line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/soduku.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "# Grayscale and Canny Edges extracted\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize = 3)\n",
    "\n",
    "# Run HoughLines using a rho accuracy of 1 pixel\n",
    "# theta accuracy of np.pi / 180 which is 1 degree\n",
    "# Our line threshold is set to 240 (number of points on line)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 240)\n",
    "\n",
    "# We iterate through each line and convert it to the format\n",
    "# required by cv2.lines (i.e. requiring end points)\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('Hough Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic Hough Lines\n",
    "\n",
    "**cv2.HoughLinesP(binarized image, 𝜌 accuracy, 𝜃 accuracy, threshold, minimum line length, max line gap)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Grayscale and Canny Edges extracted\n",
    "image = cv2.imread('images/soduku.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize = 3)\n",
    "\n",
    "# Again we use the same rho and theta accuracies\n",
    "# However, we specific a minimum vote (pts along line) of 100\n",
    "# and Min line length of 5 pixels and max gap between lines of 10 pixels\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 200, 5, 10)\n",
    "print(lines.shape)\n",
    "\n",
    "for x in range(0, len(lines)):\n",
    "    for x1,y1,x2,y2 in lines[x]:\n",
    "        cv2.line(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('Probabilistic Hough Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circle Detection - Hough Cirlces\n",
    "\n",
    "**cv2.HoughCircles**(image, method, dp, MinDist, param1, param2, minRadius, MaxRadius)\n",
    "\n",
    "\n",
    "- Method - currently only cv2.HOUGH_GRADIENT available\n",
    "- dp - Inverse ratio of accumulator resolution\n",
    "- MinDist - the minimum distance between the center of detected circles\n",
    "- param1 - Gradient value used in the edge detection\n",
    "- param2 - Accumulator threshold for the HOUGH_GRADIENT method (lower allows more circles to be detected (false positives))\n",
    "- minRadius - limits the smallest circle to this size (via radius)\n",
    "- MaxRadius - similarly sets the limit for the largest circles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/opencv.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 20)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(image,(i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "    \n",
    "    # draw the center of the circle\n",
    "    cv2.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n",
    "\n",
    "cv2.imshow('detected circles', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread(\"images/Sunflowers.jpg\")\n",
    " \n",
    "# Set up the detector with default parameters.\n",
    "detector =cv2.SimpleBlobDetector_create()\n",
    " \n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(image)\n",
    " \n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n",
    "# the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1)) \n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0),\n",
    "                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    " \n",
    "# Show keypoints\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **cv2.drawKeypoints** takes the following arguments:\n",
    "\n",
    "**cv2.drawKeypoints**(input image, keypoints, blank_output_array, color, flags)\n",
    "\n",
    "flags:\n",
    "- cv2.DRAW_MATCHES_FLAGS_DEFAULT\n",
    "- cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n",
    "- cv2.DRAW_MATCHES_FLAGS_DRAW_OVER_OUTIMG\n",
    "- cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
